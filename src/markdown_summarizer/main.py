"""
Streamlit sample : Markdown ãƒãƒ¼ãƒˆã‚’ ChatGPT ã§è¦ç´„ & ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
"""

import json

import streamlit as st
import tiktoken
from openai import OpenAI
from pydantic import BaseModel

from src.libs.settings import settings

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   ãƒšãƒ¼ã‚¸è¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Markdown Summarizer", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ Markdown Summarizer & Keyword Extractor")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   API ã‚­ãƒ¼ç¢ºèª
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not settings.openai_api_key:
    st.error("OpenAI API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã« OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

client = OpenAI(api_key=settings.openai_api_key)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   å…¥åŠ›: ãƒ•ã‚¡ã‚¤ãƒ« or ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
uploaded = st.file_uploader(
    "Markdown (.md / .txt) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«ç›´æ¥è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„",
    type=["md", "txt"],
)

default_md = """\
# ğŸŒ 2025Â Q2 LLM Megareport
*â€œæŠ€è¡“ãƒ»ãƒ“ã‚¸ãƒã‚¹ãƒ»æ”¿ç­–ã‚’ 360Â° ä¿¯ç°ã™ã‚‹ 40Â Kâ€‘word ãƒ­ãƒ³ã‚°ãƒªãƒ¼ãƒ‰â€*

---

## ğŸ“œ ç›®æ¬¡
1. [ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ï¼‰](#ch1)
2. [ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ & æº–ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«](#ch2)
3. [ã‚³ã‚¢æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰è©³ç´°](#ch3)
4. [ã‚¤ãƒ³ãƒ•ãƒ© & ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢](#ch4)
5. [è¦åˆ¶ãƒ»ã‚¬ãƒãƒŠãƒ³ã‚¹](#ch5)
6. [ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ & è©•ä¾¡](#ch6)
7. [å•†ç”¨ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ](#ch7)
8. [ç ”ç©¶ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ & æœªè§£æ±ºèª²é¡Œ](#ch8)
9. [12Â ã‹æœˆäºˆæ¸¬ã¨æˆ¦ç•¥æŒ‡é‡](#ch9)
10. [AppendixÂ AÂ â€”Â ç”¨èªé›† & ç•¥èª](#appA)

---

<a name="ch1"></a>
## 1ï¸âƒ£ ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ï¼‰

> **è¦ç‚¹** â€• 3Â ç¤¾ 6Â ç³»çµ±ãŒ â€œæ€§èƒ½Ã—ã‚³ã‚¹ãƒˆÃ—ãƒ¢ãƒ¼ãƒ€ãƒ«â€ ã®ä¸‰è§’å½¢ã§ç«¶åˆã€‚GPTâ€‘4o ã¨ ClaudeÂ 3 Opus ãŒé•·æ–‡è„ˆãƒ»ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã§å…ˆè¡Œã—ã€GeminiÂ 2.5 ãŒ**æ¨è«–äºˆç®— API**ã§ã‚³ã‚¹ãƒˆåˆ¶å¾¡ã«é©æ–°ã‚’èµ·ã“ã—ãŸã€‚

### 1â€‘A. **OpenAI**
| ãƒ¢ãƒ‡ãƒ« | æ§‹é€  | ä¸»ãªæ©Ÿèƒ½ | API ä¾¡æ ¼* |
| --- | --- | --- | --- |
| **GPTâ€‘4o** | Vision+Audio+Text çµ±åˆ Transformer | 2Ã— é€Ÿ / Â½ ä¾¡æ ¼ / 5Ã— Rateâ€‘LimitÂ  [oai_citation_attribution:0â€¡OpenAI](https://openai.com/index/hello-gpt-4o/?utm_source=chatgpt.com) | \\$5/M **out**, \\$1/M **in** |
| **o3** | 8Â T ç·ãƒ‘ãƒ©ã® Gradientâ€‘MoE | å°‚é–€å®¶æ¯”ç‡ 3Â % ã§ GPTâ€‘4 åŒç­‰Â  [oai_citation_attribution:1â€¡OpenAI](https://openai.com/index/introducing-4o-image-generation/?utm_source=chatgpt.com) | \\$0.8/M in |
| **o4â€‘mini** | 46Â B å¯†çµåˆ + LoRA | GPTâ€‘3.5â†’4.5 ã®éš™é–“Â  [oai_citation_attribution:2â€¡OpenAI Help Center](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4-gpt-4o-and-gpt-4o-mini?utm_source=chatgpt.com) | \\$0.5/M in |

> ğŸ’¡ **API ã‚¹ãƒ‹ãƒšãƒƒãƒˆ**
> ```python
> client.chat.completions.create(
>   model="gpt-4o",
>   messages=[{"role":"system","content":"You are a RAG agent."}, ...],
>   tools=[{"type":"retrieval"}],
>   max_tokens=4096, temperature=0.3
> )
> ```

#### *å†…éƒ¨å®Ÿè£…*
- **Router**: Topâ€‘k=2 softmax ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
- **KVâ€‘Cache**: Bfloat16â†’FP4 åœ§ç¸® (Blackwelläº’æ›)
- **Speculative Decoding**: Fastâ€‘Draft 4â€‘stepâ†’Verifier

---

### 1â€‘B. **AnthropicÂ ClaudeÂ 3**
> ğŸ“ *â€œStretchâ€‘RoPEâ€ ã«ã‚ˆã‚Š **1Â MÂ tokens** ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’å®Ÿç”¨åŒ–*

| Variant | æ–‡è„ˆé•· | å®šè©•ãƒ™ãƒ³ãƒ | ä¾¡æ ¼ (in/out) | ç”¨é€”ä¾‹ |
| --- | --- | --- | --- | --- |
| Haiku | 200Â K | GSM8KÂ 82Â % | \\$0.25 / \\$1 | FAQ Bot |
| Sonnet | 400Â K | MMLUÂ 87Â % | \\$1.5 / \\$5 | RAG+åˆ†æ |
| **Opus** | **1Â M** | CodeforcesÂ 1900+ | \\$6 / \\$15 | è¤‡åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ |

> > **Blockquote: Opus é–‹ç™ºè€…è«‡**
> > *â€œWindowed Compression ã«ã‚ˆã£ã¦ã€128Â K è¶…ã® KVâ€‘Cache ã‚’ GPUÂ HBM 64Â GB å†…ã«åã‚ãŸã€‚â€*

---

### 1â€‘C. **GoogleÂ GeminiÂ 2.5 / 2.5Â Flash**
- **Thinkingâ€‘Budget** ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ `steps`Ã—`breadth` ã‚’åˆ¶å¾¡ã—ã€å‘¼ã³å‡ºã—å´ã§ *å“è³ªâ€‘é…å»¶â€‘ã‚³ã‚¹ãƒˆ* ã‚’æ•°å¼çš„ã«æœ€é©åŒ–ã€‚
- Flash ç‰ˆã¯æ¢ç´¢å¹…ã‚’ 1/2 ã«ç¸®å°ã— **ã‚³ã‚¹ãƒˆâ€‘68Â %**ï¼*å“è³ªâ€‘35Â %*

```mermaid
flowchart LR
  User -->|Budget=0| Gemini{Search}
  Gemini -->|Docs| RAG
  RAG -->|Budget=5| Gemini
  Gemini --> Answer
```

---

<a name="ch2"></a>
## 2ï¸âƒ£ ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ & æº–ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«

### 2â€‘A. **MetaÂ LlamaÂ 4**
Meta ã¯ *ScoutÂ 17Â B / MaverickÂ 140Â B / BehemothÂ 2Â T* ã‚’ç™ºè¡¨ã€‚Scout & Maverick ã¯ **MoE + ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«** ã® OSSã€Behemoth ã¯æ•™å¸«ãƒ¢ãƒ‡ãƒ«Â  [oai_citation_attribution:3â€¡Log in or sign up to view](https://about.fb.com/ja/news/2025/04/llama-4-multimodal-intelligence/?utm_source=chatgpt.com)ã€‚

| Variant | ActiveÂ Params | Experts | MaxÂ Ctx | DLâ€‘ArenaÂ ELO |
| --- | --- | --- | --- | --- |
| Scout | 17Â B | 16 | 10Â M | 1298 |
| Maverick | 17Â B | 128 | 10Â M | 1417 |
| Behemoth | 288Â B | 16 | **è¨“ç·´ä¸­** | â€” |

> âœ… **HuggingÂ Face** ã§å³ DL â†’ `pip install llama4-scout`

---

### 2â€‘B. **DeepSeekâ€‘R1Â 671Â B**
MIT ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ â‘ å®Œå…¨ã‚ªãƒ¼ãƒ—ãƒ³ã€â‘¡MoTE=â€œMixtureâ€‘ofâ€‘Topâ€‘Expertsâ€ã€‚æ´»æ€§ãƒ‘ãƒ© 44Â B ã§ GPTâ€‘4â€‘classã€‚ã€ä¾¡æ ¼ã€‘\\$0.14/M inÂ  [oai_citation_attribution:4â€¡Your First API Call | DeepSeek API Docs](https://api-docs.deepseek.com/news/news250120?utm_source=chatgpt.com)

> ```bash
> accelerate launch deepseek_inference.py \
>   --model deepseek-reasoner --dtype int4_bcq
> ```

### 2â€‘C. ãã®ä»– OSS
- **MixtralÂ 8Ã—22Â B** â€‘ 7â€‘bitÂ W/A é‡å­åŒ–ã§Â M2Â ä¸Š 25Â tokÂ sâ»Â¹Â  [oai_citation_attribution:5â€¡OpenAI Community](https://community.openai.com/t/api-for-image-generation-for-gpt-4o-model/1153132?utm_source=chatgpt.com)
- **Phiâ€‘3â€‘miniâ€‘128K** â€‘ 3.8Â B ã§ã‚‚ GPTâ€‘3.5 åŒç­‰ï¼ˆMicrosoftï¼‰
- **Qwenâ€‘2** â€‘ gQA + åƒå„„ã‚³ãƒ¼ãƒ‘ã‚¹ã€ä¸­å›½èªã‚¿ã‚¹ã‚¯é¦–ä½

---

<a name="ch3"></a>
## 3ï¸âƒ£ ã‚³ã‚¢æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰è©³ç´°

### 3â€‘1. **Mixtureâ€‘ofâ€‘Experts (MoE)**

| Router | æ–¹å¼ | ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ | Comm.Â Overhead |
| --- | --- | --- | --- |
| Switchâ€‘MLP | tokenâ€‘wise K=1 | â˜…â˜…â˜…â˜…â˜† | â–² gRPC å¤šç™º |
| GradientÂ Router (o3) | K=2 + Clip | â˜…â˜…â˜…â˜…â˜… | â— ä½ |
| **HierarchicalÂ Router** (Meta) | 2â€‘level | â˜…â˜…â˜…â˜…â˜… | â—Â â€‘48Â %Â bandÂ useÂ  [oai_citation_attribution:6â€¡Log in or sign up to view](https://about.fb.com/ja/news/2025/04/llama-4-multimodal-intelligence/?utm_source=chatgpt.com) |

> **æ•°å¼**
> $$\text{MoE\\_Loss} = \\mathcal{L}_{\text{task}} + \\lambda \\sum_g (\text{load}_g - \bar{\text{load}})^2$$
> *Î»*=0.01 ã§ loadâ€‘balancing æå¤±ã‚’å‹¾é…ã® 2Â % ä»¥ä¸‹ã«æŠ‘åˆ¶ã€‚

---

### 3â€‘2. **é•·æ–‡è„ˆæŠ€è¡“**
1. **Stretchâ€‘RoPE**: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•° *Î±* ã‚’ãƒˆãƒ¼ã‚¯ãƒ³ä½ç½®ã§å¯å¤‰ã«ã€‚(Claude)
2. **Dynamicâ€‘NTK**: `exp(iÂ·posÂ·Î¸/NTK(pos))` ã® NTK ã‚’å¯¾æ•°ç¸®å°ã€‚
3. **Windowed Compression**: å¤ã„ KVâ€‘Cache ã‚’ 8â€‘bit â†’ 4â€‘bit è¦ç´„å¾Œ 1/8 ã‚µã‚¤ã‚ºã«åç´ã€‚

```ascii
CTX 0-----128K====256K==...==1M
       â†‘RoPEç›´  â†‘NTK   â†‘WinCompr
```

---

### 3â€‘3. **é‡å­åŒ– & çœãƒ¡ãƒ¢ãƒª**
- **BCQ (Blockâ€‘Clustered Quantization)**: W4A4 ã§ <Â 1Â % æå¤±Â  [oai_citation_attribution:7â€¡OpenAI Cookbook](https://cookbook.openai.com/examples/gpt4-1_prompting_guide?utm_source=chatgpt.com)
- **FP4**: Blackwell TensorCore å¯¾å¿œã€‚
- **gQA**: KV ã‚’ Head=1 ã«é›†ç´„ã€é•·æ–‡è„ˆã§ 1.7Ã— é€Ÿã€‚

> **å®Ÿé¨“** (LlamaÂ 4Â Maverick)
> | dtype | 32Â K ctx tokÂ sâ»Â¹ | perplexity |
> |---|---|---|
> | FP16 | 560 | 5.7 |
> | **FP4** | **1320** | 5.9 |

---

<a name="ch4"></a>
## 4ï¸âƒ£ ã‚¤ãƒ³ãƒ•ãƒ© & ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢

### 4â€‘1. GPU ã‚¹ãƒšãƒƒã‚¯æ¯”è¼ƒ

| GPU | FP16Â TFLOPS | FP4 | HBM | MaxÂ Ctxâ€  | Ref |
| --- | --- | --- | --- | --- | --- |
| **NVIDIAÂ B200** | 145 | âœ… | 192Â GB | 256Â K |  [oai_citation_attribution:8â€¡NVIDIA](https://resources.nvidia.com/en-us-blackwell-architecture/blackwell-architecture-technical-brief?utm_source=chatgpt.com) |
| **Graceâ€‘BlackwellÂ GB200Â NVL72** | 1.44Â PF | âœ… | 8Â TB (NVSwitch) | 4Â M | åŒä¸Š |
| AMDÂ MI300X | 130 | âŒ | 192Â GB | 128Â K | â€” |
| IntelÂ FalconÂ Shores | 85 | âŒ | 128Â GB | 64Â K | (roadmap) |

â€ æ¨è«–æ™‚ vLLM + chunkedâ€‘prefill å‰æ

> > âš™ï¸ **é‹ç”¨ Tip**
> > â€œGB200Â NVL72 Ã— vLLMÂ 0.4â€ ã§ GPTâ€‘4â€‘class ã‚’ 1Â KÂ tokÂ sâ»Â¹Â /Â nodeã€é›»åŠ› 4.2Â kWã€è©¦ç®—ã€‘ã€‚

---

<a name="ch5"></a>
## 5ï¸âƒ£ è¦åˆ¶ãƒ»ã‚¬ãƒãƒŠãƒ³ã‚¹

### 5â€‘A. **EUÂ AIÂ Act (RegÂ 2024/1689)**
- **ä¸€èˆ¬ç›®çš„ AI (GPAI)** ãƒ—ãƒ­ãƒã‚¤ãƒ€ã¯
  1. ãƒˆãƒ¬ãƒ‡ãƒ¼ã‚¿è¦ç´„å…¬é–‹
  2. æŠ€è¡“æ–‡æ›¸æå‡º
  3. ã€ŒAIÂ Officeã€ç™»éŒ²
  4. ãƒªã‚¹ã‚¯ç®¡ç†ä½“ç³»ã®å…¬è¡¨Â  [oai_citation_attribution:9â€¡EUR-Lex](https://eur-lex.europa.eu/legal-content/EN/LSU/?uri=oj%3AL_202401689&utm_source=chatgpt.com)

> **ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³**
> - 2025â€‘08Â : ãƒˆãƒ©ãƒ³ã‚¹ãƒšã‚¢ãƒ¬ãƒ³ã‚·ãƒ¼æ¡é …ç™ºåŠ¹
> - 2026â€‘02Â : GPAI è©•ä¾¡åŸºæº–ã‚’ EU æ¨™æº–åŒ–æ©Ÿæ§‹ãŒåˆ¶å®š

### 5â€‘B. **ç±³å›½ EOÂ 14110 â†’ 2025Â EO æ”¹è¨‚**
- 2023Â EOÂ 14110ï¼ˆBidenï¼‰â€¦ å®‰å…¨æ€§ãƒ»ãƒ¬ãƒƒãƒ‰ãƒãƒ¼ãƒ ç¾©å‹™Â  [oai_citation_attribution:10â€¡The White House](https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/?goal=0_7f08f27dbf-f00f5eef50-54576006&utm_source=chatgpt.com)
- 2025Â EOï¼ˆTrumpï¼‰â€¦ å ±å‘Šç¾©å‹™ç·©å’Œãƒ»ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ä¿ƒé€²Â  [oai_citation_attribution:11â€¡The White House](https://www.whitehouse.gov/fact-sheets/2025/01/fact-sheet-president-donald-j-trump-takes-action-to-enhance-americas-ai-leadership/?utm_source=chatgpt.com)

| äº‹é … | 2023 EO | 2025 EO |
| --- | :white_check_mark: | :x: |
| ãƒ¬ãƒƒãƒ‰ãƒãƒ¼ãƒ çµæœ DoC æå‡º | âœ… | âŒ |
| Frontier è¨“ç·´è¨ˆç®—é‡å ±å‘Š | âœ… | âŒ |
| **ã‚µã‚¤ãƒãƒ¼å®‰å…¨ç›£æŸ»** | âœ… | âœ… |

---

<a name="ch6"></a>
## 6ï¸âƒ£ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ & è©•ä¾¡

### 6â€‘A. **HELMÂ 2.0**
25 èƒ½åŠ› Ã— 30 ã‚·ãƒŠãƒªã‚ªã®ã‚¹ã‚³ã‚¢ãƒãƒˆãƒªã‚¯ã‚¹ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’ â€œSpiderâ€ ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã§è¡¨ç¤ºÂ  [oai_citation_attribution:12â€¡OpenAI Community](https://community.openai.com/t/the-official-4o-and-dall-e-image-megathread/1230134?utm_source=chatgpt.com)

### 6â€‘B. **Chatbot Arena (v2)**
- 4Â æœˆç‰ˆã§ GPTâ€‘4o ãŒ 1Â ä½ (ELOÂ 1468)ã€Llamaâ€‘4Â Maverick ãŒ 2Â ä½ (ELOÂ 1417)ã€‚
- Llama å´ãŒ â€œè’¸ç•™â‰’å•é¡Œãƒªãƒ¼ã‚¯â€ ç–‘ç¾©â†’ **è©•ä¾¡å†è¨­è¨ˆ** å§‹å‹•ã€‚

```python
# vLLM-based automated Arena evaluator
from vllm import LLM, SamplingParams
llm = LLM("scout-llama4-int4")
sp = SamplingParams(temperature=0, max_tokens=1)
score = compare_pair(llm, reference_model="gpt-4o", dataset="arena-hard")
```

---

<a name="ch7"></a>
## 7ï¸âƒ£ å•†ç”¨ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ 

### 7â€‘1. MaaS ä¾¡æ ¼è¡¨ (2025â€‘04)

| Provider | Flagship | \\$ / M in | \\$ / M out | å‚™è€ƒ |
| --- | --- | --- | --- | --- |
| OpenAI | GPTâ€‘4o | **1.0** | **5.0** |
| Anthropic | ClaudeÂ Opus | 6.0 | 15.0 |
| Google | GeminiÂ 2.5 | 0.6 | 3.0 |
| DeepSeek | R1 | 0.14 | 2.19 |
| Mistral | MixtralÂ 8x22B | 0.2 | 1.5 |

> **ã‚¢ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹æ½®æµ**
> - LambdaÂ Hyperplane (8Ã—B200)
> - GroqÂ Rack (Gaudi3 ASIC)
> - CerebrasÂ CSâ€‘3 RAGâ€‘Ready

---

<a name="ch8"></a>
## 8ï¸âƒ£ ç ”ç©¶ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ & æœªè§£æ±ºèª²é¡Œ

| èª²é¡Œ | é€²å±• | æœªè¸ãƒã‚¤ãƒ³ãƒˆ |
| --- | --- | --- |
| ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ | Agenticâ€‘RAG ã§ â–²50Â % | **Sourceâ€‘Tight Loss** æœªæ™®åŠ |
| è‡ªå·±æ¤œè¨¼ | GPTâ€‘o3 å†…åŒ… | ã‚³ã‚¹ãƒˆ â†” ä½é…å»¶ |
| ASLâ€‘3 å®‰å…¨æ°´æº– | OpusÂ v2 Î² | æ„å›³â€‘éš è”½æ¤œçŸ¥ |
| åˆæˆãƒ‡ãƒ¼ã‚¿ | GPTâ€‘4o Selfâ€‘Play | åˆ†å¸ƒã‚·ãƒ•ãƒˆç®¡ç† |

> **ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆ**
> - [ ] RoPE+NTK ã®ã‚¹ã‚±ãƒ¼ãƒ«ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
> - [ ] BCQ ã‚«ãƒ¼ãƒãƒ«ã‚’ Triton ã§æ‹¡å¼µ
> - [ ] EUÂ AIÂ Act ãƒªã‚¹ã‚¯å ±å‘Šãƒ†ãƒ³ãƒ—ãƒ¬ä½œæˆ

---

<a name="ch9"></a>
## 9ï¸âƒ£ 12Â ã‹æœˆäºˆæ¸¬ã¨æˆ¦ç•¥æŒ‡é‡

1. **Edgeâ€‘MoE** PC (20â€‘70Â B) â†’ ãƒ­ãƒ¼ã‚«ãƒ« AI ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰
2. **ASLâ€‘3**: è¡Œå‹•éš è”½æ¤œçŸ¥å™¨å®Ÿè£… â†’ API ä»˜åŠ ä¾¡å€¤
3. **IDEÂ Ã—Â Agenticâ€‘RAG** â†’ ã‚³ãƒ¼ãƒ‰æ”¹ä¿®ã¾ã§è‡ªå‹•
4. **åˆæˆï¼‹å®Ÿãƒ‡ãƒ¼ã‚¿ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å­¦ç¿’** ç«¶äº‰
5. **ãƒªãƒ¼ã‚¸ãƒ§ãƒ³åˆ†å‰² API**ï¼šEUâ€‘Only ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç¾©å‹™åŒ–

> > â€œ**è¨ˆç”»â†’ãƒ‡ã‚¶ã‚¤ãƒ³â†’å®Ÿè£…** ã®å…¨ãƒ•ã‚§ãƒ¼ã‚ºã§ *RiskÂ &Â Compliance byÂ Design* ãŒå¿…é ˆã«ãªã‚‹â€

---

<a name="appA"></a>
## AppendixÂ AÂ â€”Â ç”¨èªé›† & ç•¥èª

| ç•¥èª | æ„å‘³ |
| --- | --- |
| **MoE** | Mixtureâ€‘ofâ€‘Experts |
| **gQA** | Grouped Query Attention |
| **BCQ** | Blockâ€‘Clustered Quantization |
| **RAG** | Retrievalâ€‘Augmented Generation |
| **ASL** | Anthropic Safety Level |
| **GPAI** | Generalâ€‘Purpose AI (EUÂ AIÂ Act) |

---

> Â©Â 2025Â LLM Megareport. å¼•ç”¨ãƒ»è»¢è¼‰æ™‚ã¯æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ URL ã‚’ä½µè¨˜ã—ã¦ãã ã•ã„ã€‚
> *PreparedÂ for advanced practitioners & policy designers.*

---

[^*]: API ä¾¡æ ¼ã¯ 2025â€‘04â€‘15 æ™‚ç‚¹å…¬å¼ç™ºè¡¨ã«åŸºã¥ãã€‚

<!-- â¬†ï¸ ãƒšãƒ¼ã‚¸ä¸Šéƒ¨ã¸æˆ»ã‚‹ â†’ `[Ctrl]+[Home]` -->
"""

text_input = st.text_area(
    "â–¼ ç›´æ¥å…¥åŠ›ã™ã‚‹å ´åˆã¯ã“ã¡ã‚‰",
    default_md if uploaded is None else "",
    height=250,
)

# å†å®Ÿè¡Œãƒœã‚¿ãƒ³
rerun_button = st.button("ğŸ”„ ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤‰æ›´ã—ã¦å†å®Ÿè¡Œ", type="primary")

if uploaded:
    text_md = uploaded.read().decode("utf-8")
elif text_input.strip():
    text_md = text_input
else:
    st.info("Markdown ã‚’å…¥åŠ›ï¼ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    st.stop()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   structured output ç”¨ãƒ¢ãƒ‡ãƒ«
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SummaryResponse(BaseModel):
    summary: str
    keywords: list[str]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   OpenAI ã¸å•ã„åˆã‚ã›
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner="ChatGPT ãŒè¦ç´„ä¸­ã§ã™â€¦")
def call_openai(md: str) -> SummaryResponse:
    """
    OpenAI API ã‚’ä½¿ç”¨ã—ã¦ Markdown ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã™ã‚‹ã€‚
    StructuredÂ output ã‚’ç”¨ã„ã‚‹ãŸã‚æ–‡å­—åˆ—ãƒ‘ãƒ¼ã‚¹ã¯ä¸è¦ã€‚
    """
    # å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®è»½ã„æ¤œæŸ»ï¼ˆæ¥µç«¯ãªé•·æ–‡ã®ã¨ãã«è­¦å‘Šã—ãŸã„å ´åˆãªã©ã«ä½¿ç”¨ï¼‰
    enc = tiktoken.get_encoding("cl100k_base")
    _ = len(enc.encode(md))

    system_msg = (
        "ã‚ãªãŸã¯å„ªç§€ãªæ—¥æœ¬èªç·¨é›†è€…ã§ã™ã€‚\n"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰æ¸¡ã•ã‚Œã‚‹ Markdown ãƒãƒ¼ãƒˆã‚’ 300 æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã€ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æœ€å¤§ 10 èªæŠ½å‡ºã—ã¦ä¸‹ã•ã„ã€‚\n"
        'å‡ºåŠ›ã¯ JSON ã§ {"summary": ..., "keywords": [...]} å½¢å¼ã¨ã—ã¾ã™ã€‚'
    )

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0.3,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": md},
        ],
        max_tokens=600,
    )

    # content ã¯å¿…ãš JSON æ–‡å­—åˆ—ã§è¿”ã‚‹
    data = json.loads(response.choices[0].message.content or "{}")
    return SummaryResponse(**data)


# ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
if rerun_button:
    call_openai.clear()  # type: ignore[attr-defined]
    st.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚æ–°ã—ã„è¦ç´„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

with st.spinner("OpenAI ã¸å•ã„åˆã‚ã›ä¸­â€¦"):
    result = call_openai(text_md)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   çµæœè¡¨ç¤º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“„ å…¥åŠ› Markdownï¼ˆæŠœç²‹ï¼‰")
MAX_LEN = 2000
st.code(text_md[:MAX_LEN] + (" â€¦" if len(text_md) > MAX_LEN else ""), language="markdown")

st.subheader("ğŸ“ è¦ç´„")
st.write(result.summary)

st.subheader("ğŸ”‘ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
st.write(", ".join(result.keywords))

st.download_button("ğŸ”½ è¦ç´„ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ä¿å­˜", result.summary, file_name="summary.txt")
